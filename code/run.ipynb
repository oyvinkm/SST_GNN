{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprocessing.utils.normalization import get_stats\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from train import train\n",
    "from utils.visualization import save_plots\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "\n",
    "for args in [\n",
    "        {'model_type': 'autoencoder',  \n",
    "         'num_layers': 4,\n",
    "         'batch_size': 16, \n",
    "         'hidden_dim': 64, \n",
    "         'epochs': 500,\n",
    "         'opt': 'adam', \n",
    "         'opt_scheduler': 'none', \n",
    "         'opt_restart': 0, \n",
    "         'weight_decay': 5e-4, \n",
    "         'lr': 0.001,\n",
    "         'train_size': 100, \n",
    "         'test_size': 40, \n",
    "         'device':'cuda',\n",
    "         'shuffle': True, \n",
    "         'save_velo_val': True,\n",
    "         'save_best_model': False, \n",
    "         'checkpoint_dir': './best_models/',\n",
    "         'postprocess_dir': './2d_loss_plots/'},\n",
    "    ]:\n",
    "        args = objectview(args)\n",
    "\n",
    "#To ensure reproducibility the best we can, here we control the sources of\n",
    "#randomness by seeding the various random number generators used in this Colab\n",
    "#For more information, see: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.manual_seed(5)  #Torch\n",
    "random.seed(5)        #Python\n",
    "np.random.seed(5)     #NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "args.device = device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load('data/trajectories/trajectory_0.pt')[:(args.train_size+args.test_size)]\n",
    "stats_list = get_stats(dataset)\n",
    "loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiscale Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_scatter\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, Sequential, LayerNorm, ReLU\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ProcessorLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels,  **kwargs):\n",
    "        super(ProcessorLayer, self).__init__(  **kwargs )\n",
    "        \"\"\"\n",
    "        in_channels: dim of node embeddings [128], out_channels: dim of edge embeddings [128]\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Note that the node and edge encoders both have the same hidden dimension\n",
    "        # size. This means that the input of the edge processor will always be\n",
    "        # three times the specified hidden dimension\n",
    "        # (input: adjacent node embeddings and self embeddings)\n",
    "        self.edge_mlp = Sequential(Linear( 3* in_channels , out_channels),\n",
    "                                   ReLU(),\n",
    "                                   Linear( out_channels, out_channels),\n",
    "                                   LayerNorm(out_channels))\n",
    "\n",
    "        self.node_mlp = Sequential(Linear( 2* in_channels , out_channels),\n",
    "                                   ReLU(),\n",
    "                                   Linear( out_channels, out_channels),\n",
    "                                   LayerNorm(out_channels))\n",
    "\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        reset parameters for stacked MLP layers\n",
    "        \"\"\"\n",
    "        self.edge_mlp[0].reset_parameters()\n",
    "        self.edge_mlp[2].reset_parameters()\n",
    "\n",
    "        self.node_mlp[0].reset_parameters()\n",
    "        self.node_mlp[2].reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, size = None):\n",
    "        \"\"\"\n",
    "        Handle the pre and post-processing of node features/embeddings,\n",
    "        as well as initiates message passing by calling the propagate function.\n",
    "\n",
    "        Note that message passing and aggregation are handled by the propagate\n",
    "        function, and the update\n",
    "\n",
    "        x has shpae [node_num , in_channels] (node embeddings)\n",
    "        edge_index: [2, edge_num]\n",
    "        edge_attr: [E, in_channels]\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        out, updated_edges = self.propagate(edge_index, x = x, edge_attr = edge_attr, size = size) # out has the shape of [E, out_channels]\n",
    "\n",
    "        updated_nodes = torch.cat([x,out],dim=1)        # Complete the aggregation through self-aggregation\n",
    "\n",
    "        updated_nodes = x + self.node_mlp(updated_nodes) # residual connection\n",
    "\n",
    "        return updated_nodes, updated_edges\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        \"\"\"\n",
    "        source_node: x_i has the shape of [E, in_channels]\n",
    "        target_node: x_j has the shape of [E, in_channels]\n",
    "        target_edge: edge_attr has the shape of [E, out_channels]\n",
    "\n",
    "        The messages that are passed are the raw embeddings. These are not processed.\n",
    "        \"\"\"\n",
    "\n",
    "        updated_edges=torch.cat([x_i, x_j, edge_attr], dim = 1) # tmp_emb has the shape of [E, 3 * in_channels]\n",
    "        updated_edges=self.edge_mlp(updated_edges)+edge_attr\n",
    "\n",
    "        return updated_edges\n",
    "\n",
    "    def aggregate(self, updated_edges, edge_index, dim_size = None):\n",
    "        \"\"\"\n",
    "        First we aggregate from neighbors (i.e., adjacent nodes) through concatenation,\n",
    "        then we aggregate self message (from the edge itself). This is streamlined\n",
    "        into one operation here.\n",
    "        \"\"\"\n",
    "\n",
    "        # The axis along which to index number of nodes.\n",
    "        node_dim = 0\n",
    "\n",
    "        out = torch_scatter.scatter(updated_edges, edge_index[0, :], dim=node_dim, reduce = 'sum')\n",
    "\n",
    "        return out, updated_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMPLayer(torch.nn.Module):\n",
    "    def __init__(self, input_dim_node, input_dim_edge, hidden_dim, output_dim, args, emb=False):\n",
    "        super(MMPLayer, self).__init__()\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        self.processor = nn.ModuleList()\n",
    "        assert (self.num_layers >= 1), 'Number of message passing layers is not >=1'\n",
    "\n",
    "        self.node_encoder = Sequential(Linear(input_dim_node , hidden_dim),\n",
    "                              ReLU(),\n",
    "                              Linear( hidden_dim, hidden_dim),\n",
    "                              LayerNorm(hidden_dim))\n",
    "\n",
    "        self.edge_encoder = Sequential(Linear( input_dim_edge , hidden_dim),\n",
    "                              ReLU(),\n",
    "                              Linear( hidden_dim, hidden_dim),\n",
    "                              LayerNorm(hidden_dim)\n",
    "                              )\n",
    "\n",
    "        processor_layer=self.build_processor_model()\n",
    "        for _ in range(self.num_layers):\n",
    "            self.processor.append(processor_layer(hidden_dim,hidden_dim))\n",
    "    \n",
    "    def build_processor_model(self):\n",
    "        return ProcessorLayer\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, pressure = data.x, data.edge_index, data.edge_attr, data.p\n",
    "         # Step 1: encode node/edge features into latent node/edge embeddings\n",
    "        x = self.node_encoder(x) # output shape is the specified hidden dimension\n",
    "        print(f'Encoded x: {x.shape}')\n",
    "        edge_attr = self.edge_encoder(edge_attr) # output shape is the specified hidden dimension\n",
    "        print(f'Encoded edge: {edge_attr.shape}')\n",
    "         # step 2: perform message passing with latent node/edge embeddings\n",
    "        for i in range(self.num_layers):\n",
    "            x,edge_attr = self.processor[i](x,edge_index,edge_attr)\n",
    "        return x, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dim node: 11\n",
      "Input dim edge: 3\n",
      "Hidden dim: 64\n",
      "Encoded x: torch.Size([1876, 64])\n",
      "Encoded edge: torch.Size([10788, 64])\n",
      "torch.Size([1876, 64])\n",
      "torch.Size([10788, 64])\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(loader))\n",
    "input_dim_node, input_dim_edge = sample.num_features, sample.edge_attr.shape[1]\n",
    "print(f'Input dim node: {input_dim_node}\\nInput dim edge: {input_dim_edge}\\nHidden dim: {args.hidden_dim}')\n",
    "model = MMPLayer(input_dim_node, input_dim_edge, args.hidden_dim, 1, args)\n",
    "x, edge_attr = model(sample)\n",
    "print(x.shape)\n",
    "print(edge_attr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from torch_geometric.nn import GAE, VGAE, GCNConv\n",
    "import copy\n",
    "from torch import tensor\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torchmetrics import Accuracy, AveragePrecision, Dice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "[mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge,mean_vec_y,std_vec_y] = stats_list\n",
    "(mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge,mean_vec_y,std_vec_y)=(mean_vec_x.to(device),\n",
    "            std_vec_x.to(device),mean_vec_edge.to(device),std_vec_edge.to(device),mean_vec_y.to(device),std_vec_y.to(device))\n",
    "sample = dataset[0].to(device)\n",
    "with torch.no_grad():\n",
    "  loss = torch.nn.CrossEntropyLoss()\n",
    "  auto_pred = auto_best_model(sample,mean_vec_x,std_vec_x).T\n",
    "  mesh_pred = mesh_best_model(sample,mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        ...,\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], device='mps:0')\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "[mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge,mean_vec_y,std_vec_y] = stats_list\n",
    "(mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge,mean_vec_y,std_vec_y)=(mean_vec_x.to(device),\n",
    "            std_vec_x.to(device),mean_vec_edge.to(device),std_vec_edge.to(device),mean_vec_y.to(device),std_vec_y.to(device))\n",
    "\n",
    "sample_1 = dataset[0].to(device)\n",
    "sample_2 = dataset[10].to(device)\n",
    "diff = sample_2.mesh_pos - sample_2.mesh_pos \n",
    "print(sample_1.mesh_pos)\n",
    "print(sample_2.mesh_pos)\n",
    "print(sample_2.mesh_pos - sample_2.mesh_pos)\n",
    "print(np.sum(diff.cpu().detach().numpy(), axis = 0))\n",
    "#edge_attr = sample.edge_attr.cpu().detach().numpy()\n",
    "# pred gives the learnt accelaration between two timsteps\n",
    "# next_vel = curr_vel + pred * delta_t  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = to_networkx(cylinder_data, to_undirected=True)\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "cent = nx.degree_centrality(G)\n",
    "node_size = list(map(lambda x: x * 500, cent.values()))\n",
    "cent_array = np.array(list(cent.values()))\n",
    "threshold = sorted(cent_array, reverse=True)[10]\n",
    "print(\"threshold\", threshold)\n",
    "cent_bin = np.where(cent_array >= threshold, 1, 0.1)\n",
    "plt.figure(figsize=(12, 12))\n",
    "nodes = nx.draw_networkx_nodes(G, pos, node_size=node_size,\n",
    "                               cmap=plt.cm.plasma,\n",
    "                               node_color=cent_bin,\n",
    "                               nodelist=list(cent.keys()),\n",
    "                               alpha=cent_bin)\n",
    "edges = nx.draw_networkx_edges(G, pos, width=0.25, alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

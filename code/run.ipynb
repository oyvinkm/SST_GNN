{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BSMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class MODE(Enum):\n",
    "    Train = 0\n",
    "    Test = 1\n",
    "    Global = 2\n",
    "\n",
    "\n",
    "def getargs():\n",
    "    parser = argparse.ArgumentParser(description='self.Args for training')\n",
    "    parser.add_argument('-case', type=str, help='cylinder/aero/plate/Font')\n",
    "    parser.add_argument('-data_dir', type=str, help='/data_dir/outputs_train(or valid, test)/. contains the datas')\n",
    "    parser.add_argument('-dump_dir', type=str, help='/dump_dir/*method/ to store ckpts, logs, trajs etc')\n",
    "    parser.add_argument('-space_dim', type=int, help='spatial dimension: 2 or 3')\n",
    "    parser.add_argument('-mode', type=int, default=0, help='0) train 1) test 2) global roll')\n",
    "\n",
    "    parser.add_argument('-n_train', type=int, default=1, help='train seq number')\n",
    "    parser.add_argument('-n_valid', type=int, default=1, help='valid seq number')\n",
    "    parser.add_argument('-n_test', type=int, default=1, help='test seq number')\n",
    "    parser.add_argument('-time_len', type=int, default=2, help='time seq length')\n",
    "\n",
    "    parser.add_argument('-noise_level', nargs='+', type=float, help='shuffle noise level vec')\n",
    "    parser.add_argument('-noise_gamma', type=float, default=1, help='1~0, 1: no effect on output;0: output has the same noise level of noise')\n",
    "\n",
    "    parser.add_argument('-recal_mesh', type=bool, default=False, help='force recalculate multi level mesh')\n",
    "    parser.add_argument('-consist_mesh', type=int, help='same mesh for every snapshots?')\n",
    "    parser.add_argument('-multi_mesh_layer', type=int, help='how many extra layer (in depth)?')\n",
    "    parser.add_argument('-mp_time', type=int, default=1, help='how many time of MP')\n",
    "    parser.add_argument('-hidden_dim', type=int, default=128, help='hidden dim of MLP')\n",
    "    parser.add_argument('-hidden_depth', type=int, default=2, help='hidden depth of MLP')\n",
    "\n",
    "    parser.add_argument('-num_epochs', type=int, default=20, help='epochs')\n",
    "    parser.add_argument('-batch', type=int, default=1, help='batch size')\n",
    "    parser.add_argument('-lr', type=float, default=1e-4, help='learning rate')\n",
    "    parser.add_argument('-gamma', type=float, default=0.93, help='decary rate')\n",
    "\n",
    "    parser.add_argument('-restart_epoch', type=int, default=-1, help='restart checkpoint epoch')\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/okm/MASTER/SST_GNN/code\n"
     ]
    }
   ],
   "source": [
    "args = getargs()\n",
    "args.space_dim=2\n",
    "args.n_train=1000\n",
    "args.n_valid=100\n",
    "args.n_test=100\n",
    "args.time_len=600\n",
    "args.noise_level=(0.02, 0.02)\n",
    "args.consist_mesh=0\n",
    "args.multi_mesh_layer=7\n",
    "args.MP_time=1\n",
    "args.num_epochs=5\n",
    "args.batch=32\n",
    "lr=0.0001\n",
    "args.gamma=0.79432823472\n",
    "args.data_dir='BSMS_GNN/data/cylinder'\n",
    "args.dump_dir='../res/cylinder'\n",
    "args.case = 'cylinder'\n",
    "args.consist_mesh = bool(args.consist_mesh)\n",
    "args.dump_dir = os.path.join('data/cylinder', 'ours')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args.device = device\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import MeshCylinderDataset as dataset_class\n",
    "from torch_geometric.loader import DataLoader\n",
    "add_noise = False\n",
    "\n",
    "#mdata = trainer.get_data(id = 2)\n",
    "mdata = dataset_class(args.data_dir,\n",
    "                      instance_id=1,\n",
    "                      layer_num=args.multi_mesh_layer,\n",
    "                      stride=1,\n",
    "                      noise_shuffle=add_noise,\n",
    "                      noise_level=args.noise_level,\n",
    "                      noise_gamma=args.noise_gamma,\n",
    "                      recal_mesh=args.recal_mesh,\n",
    "                      consist_mesh=args.consist_mesh)\n",
    "loader = DataLoader(mdata, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preproc_multi_infos(mdata, b_data, args):\n",
    "        # process the multi-level mesh for batched data here\n",
    "        # 1. if there is contact, merge multiple graphs into a big one by adding offsets (each layer)\n",
    "        _, n, _ = mdata.in_feature.shape\n",
    "            # no contact, then share the graph between batches\n",
    "            # only need to reshape input tensor\n",
    "        m_ids = mdata.m_idx\n",
    "        m_gs_list = mdata.m_g\n",
    "        m_gs = [torch.tensor(g, dtype=torch.long).to(args.device) for g in m_gs_list]\n",
    "        # reshape\n",
    "        b = b_data.edge_index.shape[1] // n\n",
    "        b_data.x = b_data.x.reshape(b, n, -1).to(args.device)\n",
    "        b_data.edge_index = b_data.edge_index.reshape(b, -1, n).to(args.device)\n",
    "        return m_ids, m_gs, b_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[1876, 5], edge_index=[2, 1876], batch=[1876], ptr=[2])\n",
      "m_ids : 950\n",
      "m_ids : 476\n",
      "m_ids : 241\n",
      "m_ids : 121\n",
      "m_ids : 67\n",
      "m_ids : 34\n",
      "m_ids : 17\n",
      "m_gs : torch.Size([2, 10788])\n",
      "m_gs : torch.Size([2, 8194])\n",
      "m_gs : torch.Size([2, 6044])\n",
      "m_gs : torch.Size([2, 5080])\n",
      "m_gs : torch.Size([2, 4484])\n",
      "m_gs : torch.Size([2, 3232])\n",
      "m_gs : torch.Size([2, 1122])\n",
      "m_gs : torch.Size([2, 272])\n",
      "b_data : DataBatch(x=[1, 1876, 5], edge_index=[1, 2, 1876], batch=[1876], ptr=[2])\n",
      "1876\n"
     ]
    }
   ],
   "source": [
    "b_data = next(iter(loader))\n",
    "print(b_data)\n",
    "m_ids, m_gs, b_data = _preproc_multi_infos(mdata, b_data, args)\n",
    "\n",
    "# m_ids holds which nodes to keep after downpooling\n",
    "for i in range(len(m_ids)):\n",
    "  print(f'm_ids : {len(m_ids[i])}')\n",
    "\n",
    "# m_gs holds which edges to keep after downpooling\n",
    "for i in range(len(m_gs)):\n",
    "  print(f'm_gs : {m_gs[i].shape}')\n",
    "\n",
    "print(f'b_data : {b_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   0,   0,  ..., 949, 949, 949],\n",
      "        [  1,   2,  29,  ..., 746, 947, 948]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 530 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/okm/MASTER/SST_GNN/code/run.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(m_gs[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m:])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m m_gs[\u001b[39m0\u001b[39;49m][m_gs[\u001b[39m1\u001b[39;49m][\u001b[39m0\u001b[39;49m:]]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 530 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiscale Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_scatter\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, Sequential, LayerNorm, ReLU\n",
    "from dataprocessing.utils.normalization import normalize\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.pool import TopKPooling\n",
    "from torch_geometric.nn.unpool import knn_interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ProcessorLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels,  **kwargs):\n",
    "        super(ProcessorLayer, self).__init__(  **kwargs )\n",
    "        \"\"\"\n",
    "        in_channels: dim of node embeddings [128], out_channels: dim of edge embeddings [128]\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Note that the node and edge encoders both have the same hidden dimension\n",
    "        # size. This means that the input of the edge processor will always be\n",
    "        # three times the specified hidden dimension\n",
    "        # (input: adjacent node embeddings and self embeddings)\n",
    "        self.edge_mlp = Sequential(Linear( 3* in_channels , out_channels),\n",
    "                                   ReLU(),\n",
    "                                   Linear( out_channels, out_channels),\n",
    "                                   LayerNorm(out_channels))\n",
    "\n",
    "        self.node_mlp = Sequential(Linear( 2* in_channels , out_channels),\n",
    "                                   ReLU(),\n",
    "                                   Linear( out_channels, out_channels),\n",
    "                                   LayerNorm(out_channels))\n",
    "\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        reset parameters for stacked MLP layers\n",
    "        \"\"\"\n",
    "        self.edge_mlp[0].reset_parameters()\n",
    "        self.edge_mlp[2].reset_parameters()\n",
    "\n",
    "        self.node_mlp[0].reset_parameters()\n",
    "        self.node_mlp[2].reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, size = None):\n",
    "        \"\"\"\n",
    "        Handle the pre and post-processing of node features/embeddings,\n",
    "        as well as initiates message passing by calling the propagate function.\n",
    "\n",
    "        Note that message passing and aggregation are handled by the propagate\n",
    "        function, and the update\n",
    "\n",
    "        x has shpae [node_num , in_channels] (node embeddings)\n",
    "        edge_index: [2, edge_num]\n",
    "        edge_attr: [E, in_channels]\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        out, updated_edges = self.propagate(edge_index, x = x, edge_attr = edge_attr, size = size) # out has the shape of [E, out_channels]\n",
    "        if x.shape[0] != out.shape[0]:\n",
    "            print(f'X : {x.shape}')\n",
    "            print(f'Out : {out.shape}')\n",
    "        updated_nodes = torch.cat([x,out],dim=1)        # Complete the aggregation through self-aggregation\n",
    "\n",
    "        updated_nodes = x + self.node_mlp(updated_nodes) # residual connection\n",
    "\n",
    "        return updated_nodes, updated_edges\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        \"\"\"\n",
    "        source_node: x_i has the shape of [E, in_channels]\n",
    "        target_node: x_j has the shape of [E, in_channels]\n",
    "        target_edge: edge_attr has the shape of [E, out_channels]\n",
    "\n",
    "        The messages that are passed are the raw embeddings. These are not processed.\n",
    "        \"\"\"\n",
    "\n",
    "        updated_edges=torch.cat([x_i, x_j, edge_attr], dim = 1) # tmp_emb has the shape of [E, 3 * in_channels]\n",
    "        updated_edges=self.edge_mlp(updated_edges)+edge_attr\n",
    "\n",
    "        return updated_edges\n",
    "\n",
    "    def aggregate(self, updated_edges, edge_index, dim_size = None):\n",
    "        \"\"\"\n",
    "        First we aggregate from neighbors (i.e., adjacent nodes) through concatenation,\n",
    "        then we aggregate self message (from the edge itself). This is streamlined\n",
    "        into one operation here.\n",
    "        \"\"\"\n",
    "\n",
    "        # The axis along which to index number of nodes.\n",
    "        node_dim = 0\n",
    "\n",
    "        out = torch_scatter.scatter(updated_edges, edge_index[0, :], dim=node_dim, reduce = 'sum')\n",
    "        return out, updated_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagePassingBlock(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim,  args, num_layers = None, emb=False):\n",
    "        super(MessagePassingBlock, self).__init__()\n",
    "        if num_layers is None:\n",
    "            self.num_layers = args.num_layers\n",
    "        else: self.num_layers = num_layers\n",
    "\n",
    "        self.processor = nn.ModuleList()\n",
    "        assert (self.num_layers >= 1), 'Number of message passing layers is not >=1'\n",
    "\n",
    "        \n",
    "\n",
    "        processor_layer=self.build_processor_model()\n",
    "        for _ in range(self.num_layers):\n",
    "            self.processor.append(processor_layer(hidden_dim,hidden_dim))\n",
    "    \n",
    "    def build_processor_model(self):\n",
    "        return ProcessorLayer\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "         # Step 1: encode node/edge features into latent node/edge embeddings\n",
    "         # step 2: perform message passing with latent node/edge embeddings\n",
    "        for i in range(self.num_layers):\n",
    "            x,edge_attr = self.processor[i](x,edge_index,edge_attr)\n",
    "        return x, edge_index, edge_attr\n",
    "\n",
    "class Unpool(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Unpool, self).__init__()\n",
    "\n",
    "    def forward(self, h, pre_node_num, idx):\n",
    "        new_h = h.new_zeros([pre_node_num, h.shape[-1]])\n",
    "        new_h[idx] = h\n",
    "        return new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagePassingLayer(torch.nn.Module):\n",
    "    def __init__(self, input_dim_node, \n",
    "                 input_dim_edge,\n",
    "                 mlp_hidden_dim,\n",
    "                 latent_dim,  \n",
    "                 output_dim,\n",
    "                 l_n,\n",
    "                 args):\n",
    "        super(MessagePassingLayer, self).__init__()\n",
    "        \"\"\"\n",
    "        args: \n",
    "        input_dim_node : number of node features\n",
    "        mlp_hidden_dim : dimension of mlp hidden layer\n",
    "        l_n : depth of messagepassing layer\n",
    "        l_d : laten dimensions\n",
    "        \"\"\"\n",
    "        self.node_encoder = Sequential(Linear(input_dim_node , mlp_hidden_dim),\n",
    "                              ReLU(),\n",
    "                              Linear( mlp_hidden_dim, mlp_hidden_dim),\n",
    "                              LayerNorm(mlp_hidden_dim))\n",
    "\n",
    "        self.edge_encoder = Sequential(Linear( input_dim_edge , mlp_hidden_dim),\n",
    "                              ReLU(),\n",
    "                              Linear( mlp_hidden_dim, mlp_hidden_dim),\n",
    "                              LayerNorm(mlp_hidden_dim)\n",
    "                              )\n",
    "        self.node_out_mlp = Sequential(Linear(mlp_hidden_dim, output_dim))\n",
    "        self.edge_out_mlp = Sequential(Linear(mlp_hidden_dim, input_dim_edge))\n",
    "        self.up_mmps = nn.ModuleList()\n",
    "        self.down_mmps = nn.ModuleList()\n",
    "        self.l_n = l_n\n",
    "        self.pools = nn.ModuleList()\n",
    "        self.bottom = MessagePassingBlock(mlp_hidden_dim, num_layers = 4, args = args)\n",
    "        for i in range(self.l_n):\n",
    "            self.down_mmps.append(MessagePassingBlock(mlp_hidden_dim, args))\n",
    "            self.up_mmps.append(MessagePassingBlock(mlp_hidden_dim, args))\n",
    "            self.pools.append(TopKPooling(mlp_hidden_dim, .5))\n",
    "        self.unpool = Unpool()\n",
    "\n",
    "    def forward(self,data,mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge):\n",
    "        \"\"\"\n",
    "        Encoder encodes graph (node/edge features) into latent vectors (node/edge embeddings)\n",
    "        The return of processor is fed into the processor for generating new feature vectors\n",
    "        \"\"\"\n",
    "        x, edge_index, edge_attr, pressure = data.x, data.edge_index, data.edge_attr, data.p\n",
    "\n",
    "        x = normalize(x,mean_vec_x,std_vec_x)\n",
    "        edge_attr=normalize(edge_attr,mean_vec_edge,std_vec_edge)\n",
    "        \n",
    "        x = self.node_encoder(x)\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "        skip_perms = [torch.arange(len(x))]\n",
    "        skip_e = [edge_index]\n",
    "        skip_x = [x]\n",
    "        skip_attr = [edge_attr]\n",
    "\n",
    "        for idx, block in enumerate(self.down_mmps):\n",
    "            x, edge_index, edge_attr = block(x, edge_index, edge_attr)\n",
    "            x, edge_index, edge_attr, _,perm,_ = self.pools[idx](x = x, edge_index = edge_index, edge_attr = edge_attr)\n",
    "            skip_x.append(x)\n",
    "            skip_perms.append(perm)\n",
    "            if idx != self.l_n -1:\n",
    "                skip_e.append(edge_index)\n",
    "                skip_attr.append(edge_attr)\n",
    "        x, _, _ = self.bottom(x, edge_index, edge_attr)\n",
    "        for idx, block in enumerate(self.up_mmps):\n",
    "            idx = self.l_n - idx - 1\n",
    "            x_idx, edge_index, edge_attr  = skip_perms.pop(), skip_e.pop(), skip_attr.pop()\n",
    "            x = self.unpool(x, skip_x[idx].shape[-2], x_idx)\n",
    "            x, _, _ = block(x, edge_index, edge_attr) \n",
    "\n",
    "        x = self.node_out_mlp(x)\n",
    "        edge_attr = self.edge_out_mlp(edge_attr)\n",
    "        return x, edge_index, edge_attr\n",
    "    \n",
    "    def loss(self, pred, inputs,mean_vec_y,std_vec_y):\n",
    "        #Define the node types that we calculate loss for\n",
    "        normal=torch.tensor(0)\n",
    "        outflow=torch.tensor(5)\n",
    "\n",
    "        #Get the loss mask for the nodes of the types we calculate loss for\n",
    "        loss_mask=torch.logical_or((torch.argmax(inputs.x[:,2:],dim=1)==torch.tensor(0)),\n",
    "                                   (torch.argmax(inputs.x[:,2:],dim=1)==torch.tensor(5)))\n",
    "\n",
    "        #Normalize labels with dataset statistics\n",
    "        labels = normalize(inputs.y,mean_vec_y,std_vec_y)\n",
    "\n",
    "        #Find sum of square errors\n",
    "        error=torch.sum((labels-pred)**2,axis=1)\n",
    "\n",
    "        #Root and mean the errors for the nodes we calculate loss for\n",
    "        loss=torch.sqrt(torch.mean(error[loss_mask]))\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from dataprocessing.utils.normalization import get_stats\n",
    "from tqdm import trange\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "\n",
    "for args in [\n",
    "        {'model_type': 'autoencoder',  \n",
    "         'num_layers': 1,\n",
    "         'batch_size': 16, \n",
    "         'hidden_dim': 64, \n",
    "         'epochs': 10,\n",
    "         'opt': 'adam', \n",
    "         'opt_scheduler': 'none', \n",
    "         'opt_restart': 0, \n",
    "         'weight_decay': 5e-4, \n",
    "         'lr': 0.001,\n",
    "         'train_size': 100, \n",
    "         'test_size': 40, \n",
    "         'device':'cuda',\n",
    "         'shuffle': True, \n",
    "         'save_velo_val': True,\n",
    "         'save_best_model': False, \n",
    "         'checkpoint_dir': './best_models/',\n",
    "         'postprocess_dir': './2d_loss_plots/'},\n",
    "    ]:\n",
    "        args = objectview(args)\n",
    "\n",
    "#To ensure reproducibility the best we can, here we control the sources of\n",
    "#randomness by seeding the various random number generators used in this Colab\n",
    "#For more information, see: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.manual_seed(5)  #Torch\n",
    "random.seed(5)        #Python\n",
    "np.random.seed(5)     #NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(args, params):\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'sgd':\n",
    "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
    "    elif args.opt == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'adagrad':\n",
    "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    if args.opt_scheduler == 'none':\n",
    "        return None, optimizer\n",
    "    elif args.opt_scheduler == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
    "    elif args.opt_scheduler == 'cos':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
    "    return scheduler, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())\n",
    "device = 'cpu' if torch.backends.mps.is_available() else 'cpu'\n",
    "args.device = device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dim node: 11\n",
      "Input dim edge: 3\n",
      "Hidden dim: 64\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.load('data/trajectories/trajectory_0.pt')[:(args.train_size+args.test_size)]\n",
    "stats_list = get_stats(dataset)\n",
    "input_dim_node, input_dim_edge = dataset[0].num_features, dataset[0].edge_attr.shape[1]\n",
    "print(f'Input dim node: {input_dim_node}\\nInput dim edge: {input_dim_edge}\\nHidden dim: {args.hidden_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model = MessagePassingLayer(input_dim_node = input_dim_node, \n",
    "                            input_dim_edge = input_dim_edge, \n",
    "                            mlp_hidden_dim = args.hidden_dim, \n",
    "                            latent_dim = args.hidden_dim,\n",
    "                            l_n = 2,\n",
    "                            output_dim=2,\n",
    "                            args = args).to(device)\n",
    "scheduler, opt = build_optimizer(args, model.parameters())\n",
    "\n",
    "# Get Dataset Stats fro normalization\n",
    "stats_list = get_stats(dataset)\n",
    "[mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge,mean_vec_y,std_vec_y] = stats_list\n",
    "(mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge,mean_vec_y,std_vec_y)=(mean_vec_x.to(device),\n",
    "        std_vec_x.to(device),mean_vec_edge.to(device),std_vec_edge.to(device),mean_vec_y.to(device),std_vec_y.to(device))\n",
    "\n",
    "loader = DataLoader(dataset, batch_size = 1, shuffle=args.shuffle)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/10 [00:01<?, ?Epochs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X : torch.Size([469, 64])\n",
      "Out : torch.Size([468, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 469 but got size 468 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/okm/MASTER/SST_GNN/code/run.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m batch\u001b[39m=\u001b[39mbatch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m opt\u001b[39m.\u001b[39mzero_grad()         \u001b[39m#zero gradients each time\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m pred, e_idx, e_attr \u001b[39m=\u001b[39m model(batch,mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mloss(pred,batch,mean_vec_y,std_vec_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()         \u001b[39m#backpropagate loss\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/master/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/okm/MASTER/SST_GNN/code/run.ipynb Cell 21\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m         skip_e\u001b[39m.\u001b[39mappend(edge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m         skip_attr\u001b[39m.\u001b[39mappend(edge_attr)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m x, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbottom(x, edge_index, edge_attr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, block \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mup_mmps):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml_n \u001b[39m-\u001b[39m idx \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/master/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/okm/MASTER/SST_GNN/code/run.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index, edge_attr):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m      \u001b[39m# Step 1: encode node/edge features into latent node/edge embeddings\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m      \u001b[39m# step 2: perform message passing with latent node/edge embeddings\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         x,edge_attr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocessor[i](x,edge_index,edge_attr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x, edge_index, edge_attr\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/master/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/okm/MASTER/SST_GNN/code/run.ipynb Cell 21\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mX : \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOut : \u001b[39m\u001b[39m{\u001b[39;00mout\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m updated_nodes \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([x,out],dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)        \u001b[39m# Complete the aggregation through self-aggregation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m updated_nodes \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_mlp(updated_nodes) \u001b[39m# residual connection\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run.ipynb#X26sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mreturn\u001b[39;00m updated_nodes, updated_edges\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 469 but got size 468 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        num_loops=0\n",
    "        for batch in loader:\n",
    "            #Note that normalization must be done before it's called. The unnormalized\n",
    "            #data needs to be preserved in order to correctly calculate the loss\n",
    "            batch=batch.to(device)\n",
    "            opt.zero_grad()         #zero gradients each time\n",
    "            pred, e_idx, e_attr = model(batch,mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge)\n",
    "            loss = model.loss(pred,batch,mean_vec_y,std_vec_y)\n",
    "            loss.backward()         #backpropagate loss\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "            num_loops+=1\n",
    "        total_loss /= num_loops\n",
    "        losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from torch_geometric.nn import GAE, VGAE, GCNConv\n",
    "import copy\n",
    "from torch import tensor\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torchmetrics import Accuracy, AveragePrecision, Dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0779,  0.0000],\n",
      "        [ 0.0394,  0.0000],\n",
      "        [ 0.0797, -0.0012],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0481, -0.0059],\n",
      "        [ 0.0000,  0.0000]])\n",
      "tensor([[ 0.5235,  0.0204],\n",
      "        [ 0.4953,  0.0437],\n",
      "        [-0.0935, -0.0593],\n",
      "        ...,\n",
      "        [-0.1523,  0.0395],\n",
      "        [-0.1693, -0.0343],\n",
      "        [-0.1128, -0.0198]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = to_networkx(cylinder_data, to_undirected=True)\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "cent = nx.degree_centrality(G)\n",
    "node_size = list(map(lambda x: x * 500, cent.values()))\n",
    "cent_array = np.array(list(cent.values()))\n",
    "threshold = sorted(cent_array, reverse=True)[10]\n",
    "print(\"threshold\", threshold)\n",
    "cent_bin = np.where(cent_array >= threshold, 1, 0.1)\n",
    "plt.figure(figsize=(12, 12))\n",
    "nodes = nx.draw_networkx_nodes(G, pos, node_size=node_size,\n",
    "                               cmap=plt.cm.plasma,\n",
    "                               node_color=cent_bin,\n",
    "                               nodelist=list(cent.keys()),\n",
    "                               alpha=cent_bin)\n",
    "edges = nx.draw_networkx_edges(G, pos, width=0.25, alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

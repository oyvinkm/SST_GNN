{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprocessing.utils.normalization import get_stats\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from train import train\n",
    "from utils.visualization import save_plots\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "\n",
    "for args in [\n",
    "        {'model_type': 'meshgraphnet',  \n",
    "         'num_layers': 10,\n",
    "         'batch_size': 1, \n",
    "         'hidden_dim': 10, \n",
    "         'num_nodes': None,\n",
    "         'epochs': 100,\n",
    "         'opt': 'adam', \n",
    "         'opt_scheduler': 'none', \n",
    "         'opt_restart': 0, \n",
    "         'weight_decay': 5e-4, \n",
    "         'lr': 0.001,\n",
    "         'train_size': 45, \n",
    "         'test_size': 10, \n",
    "         'device':'cuda',\n",
    "         'shuffle': True, \n",
    "         'save_velo_val': True,\n",
    "         'save_best_model': True, \n",
    "         'checkpoint_dir': './best_models/',\n",
    "         'postprocess_dir': './2d_loss_plots/'},\n",
    "    ]:\n",
    "        args = objectview(args)\n",
    "\n",
    "#To ensure reproducibility the best we can, here we control the sources of\n",
    "#randomness by seeding the various random number generators used in this Colab\n",
    "#For more information, see: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.manual_seed(5)  #Torch\n",
    "random.seed(5)        #Python\n",
    "np.random.seed(5)     #NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "  device = 'mps'\n",
    "elif torch.cuda.is_available():\n",
    "  device = 'cuda'\n",
    "else:\n",
    "  device = 'cpu'\n",
    "device = 'cpu'\n",
    "print(device)\n",
    "args.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3.8929e-01, 6.1321e-04, 8.7527e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        9.0618e-03, 9.0618e-03, 1.0661e-01, 0.0000e+00, 0.0000e+00]), tensor([2.4483e-01, 7.7642e-02, 3.3042e-01, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        9.4761e-02, 9.4761e-02, 3.0862e-01, 1.0000e-08, 1.0000e-08]), tensor([-3.9781e-10,  1.1050e-11,  2.0158e-02]), tensor([0.0159, 0.0148, 0.0082]), tensor([-0.1814,  0.0014]), tensor([0.9233, 0.3153])]\n",
      "55\n",
      "Data(x=[1876, 11], edge_index=[2, 10788], edge_attr=[10788, 3], y=[1876, 2], p=[1876, 1], cells=[3518, 3], mesh_pos=[1876, 2])\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.load('data/trajectories/trajectory_1.pt')[:(args.train_size+args.test_size)]\n",
    "data_stats = get_stats(dataset)\n",
    "print(data_stats)\n",
    "print(len(dataset))\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "import torch\n",
    "import torch_scatter\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, Sequential, LayerNorm, ReLU\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from dataprocessing.utils.normalization import normalize, get_stats\n",
    "from torch_geometric.nn import GAE, VGAE, GCNConv\n",
    "from torch_geometric.nn.pool import TopKPooling, global_max_pool\n",
    "from torch_geometric.nn.unpool import knn_interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1876\n",
      "GCNAutoEncoder(\n",
      "  (node_encoder): GCNEncoder(\n",
      "    (conv1): GCNConv(11, 32)\n",
      "    (pool1): TopKPooling(32, ratio=0.2, multiplier=1.0)\n",
      "    (conv2): GCNConv(32, 32)\n",
      "    (pool2): TopKPooling(32, ratio=0.2, multiplier=1.0)\n",
      "    (conv3): GCNConv(32, 64)\n",
      "    (pool3): TopKPooling(64, ratio=0.1, multiplier=1.0)\n",
      "    (pool4): TopKPooling(64, ratio=0.125, multiplier=1.0)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (mlp): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  )\n",
      "  (node_decoder): GCNDecoder(\n",
      "    (conv1): GCNConv(32, 32)\n",
      "    (conv2): GCNConv(32, 11)\n",
      "    (linear): Linear(in_features=32, out_features=1000, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim_node, hidden_dim, latent_dim  = dataset[0].num_features, 32, 32\n",
    "args.num_nodes = dataset[0].num_nodes\n",
    "print(args.num_nodes)\n",
    "model = GCNAutoEncoder(input_dim_node, hidden_dim, latent_dim, input_dim_node, args)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[1876, 11], edge_index=[2, 10788], edge_attr=[10788, 3], y=[1876, 2], p=[1876, 1], cells=[3518, 3], mesh_pos=[1876, 2], batch=[1876], ptr=[2])\n",
      "X : torch.Size([1876, 11])\n",
      "Edge index:  torch.Size([2, 10788])\n",
      "X post pool 1:  torch.Size([376, 32])\n",
      "X post pool 2:  torch.Size([76, 32])\n",
      "X post pool 3:  torch.Size([8, 64])\n",
      "X post pool 4:  torch.Size([1, 64])\n",
      "Encoded:  torch.Size([1, 64])\n",
      "Post mlp:  torch.Size([1, 32])\n",
      "torch.Size([1, 1000])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1000 and 32x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/okm/MASTER/SST_GNN/code/run_things.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(loader))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(sample)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test \u001b[39m=\u001b[39m model(sample\u001b[39m.\u001b[39;49mx\u001b[39m.\u001b[39;49mto(device), sample\u001b[39m.\u001b[39;49medge_index\u001b[39m.\u001b[39;49mto(device))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(test\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/master/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/okm/MASTER/SST_GNN/code/run_things.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPost mlp: \u001b[39m\u001b[39m'\u001b[39m, x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m n_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_decoder(x, edge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_decoder \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     e_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_decoder(x, edge_index)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/master/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/okm/MASTER/SST_GNN/code/run_things.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x, edge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/okm/MASTER/SST_GNN/code/run_things.ipynb#X30sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x, edge_index)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/master/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/master/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:229\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m             edge_index \u001b[39m=\u001b[39m cache\n\u001b[0;32m--> 229\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin(x)\n\u001b[1;32m    231\u001b[0m \u001b[39m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m    232\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(edge_index, x\u001b[39m=\u001b[39mx, edge_weight\u001b[39m=\u001b[39medge_weight,\n\u001b[1;32m    233\u001b[0m                      size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/master/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/master/lib/python3.11/site-packages/torch_geometric/nn/dense/linear.py:132\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    128\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1000 and 32x32)"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(dataset, batch_size=1)\n",
    "sample = next(iter(loader))\n",
    "print(sample)\n",
    "test = model(sample.x.to(device), sample.edge_index.to(device))\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "def train():\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    best_test_loss = np.inf\n",
    "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        count = 0\n",
    "        for __loader__, batch in enumerate(loader):\n",
    "            #Note that normalization must be done before it's called. The unnormalized\n",
    "            #data needs to be preserved in order to correctly calculate the loss\n",
    "            batch=batch[0].to(device)\n",
    "            opt.zero_grad()         #zero gradients each time\n",
    "            z = model.encode(batch.x, batch.edge_index)\n",
    "            loss = model.recon_loss(z, batch.pos_edge_label_index)\n",
    "            loss = loss + (1 / batch.num_nodes) * model.kl_loss()\n",
    "            loss.backward()         #backpropagate loss\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "            count += 1\n",
    "        total_loss /= count\n",
    "        losses.append(total_loss)\n",
    "        if epoch % (args.epochs/10) == 0:\n",
    "            print(\"train loss\", total_loss)\n",
    "\n",
    "    return losses\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    return model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = to_networkx(data, to_undirected=True)\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "cent = nx.degree_centrality(G)\n",
    "node_size = list(map(lambda x: x * 500, cent.values()))\n",
    "cent_array = np.array(list(cent.values()))\n",
    "threshold = sorted(cent_array, reverse=True)[10]\n",
    "print(\"threshold\", threshold)\n",
    "cent_bin = np.where(cent_array >= threshold, 1, 0.1)\n",
    "plt.figure(figsize=(12, 12))\n",
    "nodes = nx.draw_networkx_nodes(G, pos, node_size=node_size,\n",
    "                               cmap=plt.cm.plasma,\n",
    "                               node_color=cent_bin,\n",
    "                               nodelist=list(cent.keys()),\n",
    "                               alpha=cent_bin)\n",
    "edges = nx.draw_networkx_edges(G, pos, width=0.25, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = to_networkx(cylinder_data, to_undirected=True)\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "cent = nx.degree_centrality(G)\n",
    "node_size = list(map(lambda x: x * 500, cent.values()))\n",
    "cent_array = np.array(list(cent.values()))\n",
    "threshold = sorted(cent_array, reverse=True)[10]\n",
    "print(\"threshold\", threshold)\n",
    "cent_bin = np.where(cent_array >= threshold, 1, 0.1)\n",
    "plt.figure(figsize=(12, 12))\n",
    "nodes = nx.draw_networkx_nodes(G, pos, node_size=node_size,\n",
    "                               cmap=plt.cm.plasma,\n",
    "                               node_color=cent_bin,\n",
    "                               nodelist=list(cent.keys()),\n",
    "                               alpha=cent_bin)\n",
    "edges = nx.draw_networkx_edges(G, pos, width=0.25, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = cylinder_data.edge_index.numpy()\n",
    "print(edge_index.shape)\n",
    "edge_example = edge_index[:, np.where(edge_index[0] < 5)[0]]\n",
    "edge_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_example = np.unique(edge_example.flatten())\n",
    "plt.figure(figsize=(10, 6))\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(node_example)\n",
    "G.add_edges_from(list(zip(edge_example[0], edge_example[1])))\n",
    "nx.draw_networkx(G, with_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G)\n",
    "print(G.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get edge and node attributes\n",
    "edge_labels = nx.get_edge_attributes(G, seed=42)\n",
    "node_states = nx.get_node_attributes(G, 'state')\n",
    "pos = nx.spring_layout(G, seed=0)\n",
    "# set node state positions\n",
    "state_pos = {n: (x+0.12, y+0.05) for n, (x,y) in pos.items()}\n",
    "\n",
    "# draw graph\n",
    "nx.draw_networkx(G, pos, node_size=600)\n",
    "# draw node state labels\n",
    "nx.draw_networkx_labels(G, state_pos, labels=node_states, font_color='red')\n",
    "# draw edge attributes\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

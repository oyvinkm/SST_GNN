{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is stolen from \"https://github.com/pyg-team/pytorch_geometric/blob/master/examples/autoencoder.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GAE, VGAE, GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    # Row-normalizes the attricutes to sum up to one\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=.05, num_test=.1, is_undirected=True,\n",
    "                      # if split_labels is to true it will split positive and negative labels,\n",
    "                      # and save them in distinct attributes\n",
    "                      split_labels=True, \n",
    "                      # Add_negative_train_samples: Whether to add negative training samples for link\n",
    "                      # prediction for link prediction. negative train samples might e.g. be edges that\n",
    "                      # are not suposed to be in the graph.\n",
    "                      add_negative_train_samples=False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], edge_index=[2, 7740], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], pos_edge_label=[3870], pos_edge_label_index=[2, 3870])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Planetoid(\"\\..\", \"CiteSeer\", transform=transform)\n",
    "train_data, val_data, test_data = dataset[0]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        # Mu is the difference between the GCNE and the VGCNE\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels, out_channels = dataset.num_features, 16\n",
    "variation = \"GAE\"\n",
    "if variation == \"GAE\":\n",
    "    model = GAE(GCNEncoder(in_channels, out_channels))\n",
    "elif variation == \"VGAE\":\n",
    "    model = VGAE(VariationalGCNEncoder(in_channels, out_channels))\n",
    "else:\n",
    "    raise Exception(\"Model type not specified\")\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "    loss = model.recon_loss(z, train_data.pos_edge_label_index)\n",
    "\n",
    "    # Only relevant if we use the variational graph auto encoder\n",
    "    if variation == \"VGAE\":\n",
    "        loss = loss + (1 / train_data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Can we remove float?\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    return model.test(z, data.pos_edge_label_index, data.neg_edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, AUC: 0.6400, AP: 0.6731\n",
      "Epoch: 002, AUC: 0.6309, AP: 0.6675\n",
      "Epoch: 003, AUC: 0.6335, AP: 0.6700\n",
      "Epoch: 004, AUC: 0.6399, AP: 0.6759\n",
      "Epoch: 005, AUC: 0.6478, AP: 0.6860\n",
      "Epoch: 006, AUC: 0.6515, AP: 0.6953\n",
      "Epoch: 007, AUC: 0.6529, AP: 0.7023\n",
      "Epoch: 008, AUC: 0.6531, AP: 0.7061\n",
      "Epoch: 009, AUC: 0.6543, AP: 0.7082\n",
      "Epoch: 010, AUC: 0.6550, AP: 0.7092\n",
      "Epoch: 011, AUC: 0.6579, AP: 0.7113\n",
      "Epoch: 012, AUC: 0.6704, AP: 0.7174\n",
      "Epoch: 013, AUC: 0.7037, AP: 0.7322\n",
      "Epoch: 014, AUC: 0.7420, AP: 0.7534\n",
      "Epoch: 015, AUC: 0.7577, AP: 0.7646\n",
      "Epoch: 016, AUC: 0.7642, AP: 0.7689\n",
      "Epoch: 017, AUC: 0.7675, AP: 0.7708\n",
      "Epoch: 018, AUC: 0.7701, AP: 0.7727\n",
      "Epoch: 019, AUC: 0.7704, AP: 0.7727\n",
      "Epoch: 020, AUC: 0.7686, AP: 0.7710\n",
      "Epoch: 021, AUC: 0.7712, AP: 0.7724\n",
      "Epoch: 022, AUC: 0.7763, AP: 0.7753\n",
      "Epoch: 023, AUC: 0.7762, AP: 0.7753\n",
      "Epoch: 024, AUC: 0.7747, AP: 0.7738\n",
      "Epoch: 025, AUC: 0.7803, AP: 0.7776\n",
      "Epoch: 026, AUC: 0.7832, AP: 0.7802\n",
      "Epoch: 027, AUC: 0.7844, AP: 0.7816\n",
      "Epoch: 028, AUC: 0.7894, AP: 0.7864\n",
      "Epoch: 029, AUC: 0.8000, AP: 0.7943\n",
      "Epoch: 030, AUC: 0.8092, AP: 0.8009\n",
      "Epoch: 031, AUC: 0.8141, AP: 0.8063\n",
      "Epoch: 032, AUC: 0.8187, AP: 0.8126\n",
      "Epoch: 033, AUC: 0.8226, AP: 0.8172\n",
      "Epoch: 034, AUC: 0.8273, AP: 0.8215\n",
      "Epoch: 035, AUC: 0.8315, AP: 0.8252\n",
      "Epoch: 036, AUC: 0.8350, AP: 0.8271\n",
      "Epoch: 037, AUC: 0.8386, AP: 0.8316\n",
      "Epoch: 038, AUC: 0.8421, AP: 0.8366\n",
      "Epoch: 039, AUC: 0.8467, AP: 0.8432\n",
      "Epoch: 040, AUC: 0.8515, AP: 0.8489\n",
      "Epoch: 041, AUC: 0.8571, AP: 0.8540\n",
      "Epoch: 042, AUC: 0.8601, AP: 0.8567\n",
      "Epoch: 043, AUC: 0.8628, AP: 0.8600\n",
      "Epoch: 044, AUC: 0.8632, AP: 0.8610\n",
      "Epoch: 045, AUC: 0.8641, AP: 0.8624\n",
      "Epoch: 046, AUC: 0.8636, AP: 0.8613\n",
      "Epoch: 047, AUC: 0.8638, AP: 0.8612\n",
      "Epoch: 048, AUC: 0.8627, AP: 0.8600\n",
      "Epoch: 049, AUC: 0.8624, AP: 0.8600\n",
      "Epoch: 050, AUC: 0.8629, AP: 0.8611\n",
      "Epoch: 051, AUC: 0.8643, AP: 0.8626\n",
      "Epoch: 052, AUC: 0.8654, AP: 0.8641\n",
      "Epoch: 053, AUC: 0.8650, AP: 0.8638\n",
      "Epoch: 054, AUC: 0.8643, AP: 0.8629\n",
      "Epoch: 055, AUC: 0.8625, AP: 0.8611\n",
      "Epoch: 056, AUC: 0.8624, AP: 0.8614\n",
      "Epoch: 057, AUC: 0.8634, AP: 0.8622\n",
      "Epoch: 058, AUC: 0.8633, AP: 0.8619\n",
      "Epoch: 059, AUC: 0.8629, AP: 0.8613\n",
      "Epoch: 060, AUC: 0.8623, AP: 0.8606\n",
      "Epoch: 061, AUC: 0.8607, AP: 0.8588\n",
      "Epoch: 062, AUC: 0.8591, AP: 0.8566\n",
      "Epoch: 063, AUC: 0.8589, AP: 0.8564\n",
      "Epoch: 064, AUC: 0.8600, AP: 0.8580\n",
      "Epoch: 065, AUC: 0.8621, AP: 0.8610\n",
      "Epoch: 066, AUC: 0.8631, AP: 0.8622\n",
      "Epoch: 067, AUC: 0.8637, AP: 0.8628\n",
      "Epoch: 068, AUC: 0.8629, AP: 0.8621\n",
      "Epoch: 069, AUC: 0.8615, AP: 0.8605\n",
      "Epoch: 070, AUC: 0.8600, AP: 0.8588\n",
      "Epoch: 071, AUC: 0.8616, AP: 0.8612\n",
      "Epoch: 072, AUC: 0.8633, AP: 0.8631\n",
      "Epoch: 073, AUC: 0.8638, AP: 0.8640\n",
      "Epoch: 074, AUC: 0.8631, AP: 0.8635\n",
      "Epoch: 075, AUC: 0.8625, AP: 0.8625\n",
      "Epoch: 076, AUC: 0.8611, AP: 0.8611\n",
      "Epoch: 077, AUC: 0.8596, AP: 0.8592\n",
      "Epoch: 078, AUC: 0.8595, AP: 0.8598\n",
      "Epoch: 079, AUC: 0.8605, AP: 0.8611\n",
      "Epoch: 080, AUC: 0.8608, AP: 0.8614\n",
      "Epoch: 081, AUC: 0.8612, AP: 0.8614\n",
      "Epoch: 082, AUC: 0.8609, AP: 0.8603\n",
      "Epoch: 083, AUC: 0.8593, AP: 0.8595\n",
      "Epoch: 084, AUC: 0.8583, AP: 0.8592\n",
      "Epoch: 085, AUC: 0.8569, AP: 0.8583\n",
      "Epoch: 086, AUC: 0.8584, AP: 0.8596\n",
      "Epoch: 087, AUC: 0.8598, AP: 0.8608\n",
      "Epoch: 088, AUC: 0.8603, AP: 0.8604\n",
      "Epoch: 089, AUC: 0.8606, AP: 0.8611\n",
      "Epoch: 090, AUC: 0.8594, AP: 0.8605\n",
      "Epoch: 091, AUC: 0.8573, AP: 0.8580\n",
      "Epoch: 092, AUC: 0.8566, AP: 0.8573\n",
      "Epoch: 093, AUC: 0.8575, AP: 0.8581\n",
      "Epoch: 094, AUC: 0.8583, AP: 0.8592\n",
      "Epoch: 095, AUC: 0.8586, AP: 0.8594\n",
      "Epoch: 096, AUC: 0.8587, AP: 0.8597\n",
      "Epoch: 097, AUC: 0.8579, AP: 0.8591\n",
      "Epoch: 098, AUC: 0.8572, AP: 0.8582\n",
      "Epoch: 099, AUC: 0.8574, AP: 0.8578\n",
      "Epoch: 100, AUC: 0.8570, AP: 0.8577\n",
      "Median time per epoch: 1.4555)s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "times = []\n",
    "epochs = 100\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start = time.time()\n",
    "    loss = train()\n",
    "    auc, ap = test(test_data)\n",
    "    print(f'Epoch: {epoch:03d}, AUC: {auc:.4f}, AP: {ap:.4f}')\n",
    "    times.append(time.time() - start)\n",
    "print(f\"Median time per epoch: {torch.tensor(times).median():.4f})s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
